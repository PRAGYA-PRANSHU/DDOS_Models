{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hybrid-ml-model-for-network-intrusion-detection(1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAGYA-PRANSHU/DDOS_Models/blob/main/hybrid_ml_model_for_network_intrusion_detection(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEAgVZiXf3kq"
      },
      "source": [
        "# import relevant modules\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import imblearn\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Settings\n",
        "import sys\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "np.set_printoptions(precision=3)\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmu7Yob8f3kw"
      },
      "source": [
        "# LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lW7CRsTf3kx"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/ldap ddos data/DrDoS_LDAP_0.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/ldap ddos data/DrDoS_LDAP_1.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ht7d18Kf3k3"
      },
      "source": [
        "# SCALING NUMERICAL ATTRIBUTES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Q0GqYqf3k4"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
        "cols = train.select_dtypes(include=['float64','int64']).columns\n",
        "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
        "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
        "\n",
        "\n",
        "# turn the result back to a dataframe\n",
        "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
        "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WSaQr6pf3k6"
      },
      "source": [
        "sc_testdf = pd.DataFrame(sc_testdf)\n",
        "for col in sc_testdf.columns:\n",
        "    if 'Total Fwd Packets' in col:\n",
        "        del sc_testdf[col]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PX29oBgf3k6"
      },
      "source": [
        "# ENCODING CATEGORICAL ATTRIBUTES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9PIPvutf3k7"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# extract categorical attributes from both training and test sets \n",
        "cattrain = train.select_dtypes(include=['object']).copy()\n",
        "cattest = test.select_dtypes(include=['object']).copy()\n",
        "\n",
        "# encode the categorical attributes\n",
        "traincat = cattrain.apply(encoder.fit_transform)\n",
        "testcat = cattest.apply(encoder.fit_transform)\n",
        "\n",
        "# separate target column from encoded data \n",
        "enctrain = traincat.drop([' Label'], axis=1)\n",
        "cat_Ytrain = traincat[[' Label']].copy()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GHuQMzcf3k7",
        "outputId": "bb1c0e45-1565-4ed0-83b5-04b5c6fcdb47"
      },
      "source": [
        "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
        "train_y = train[' Label']\n",
        "train_x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pHg-D4gg0KG"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(train_x)\n",
        "train_x = imputer.transform(train_x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H4xxjblHxpm"
      },
      "source": [
        "train_x = pd.DataFrame(train_x)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjJPdsBPf3k8",
        "outputId": "912bb97e-1ce7-416a-bb5a-801b61068037"
      },
      "source": [
        "test_df = pd.concat([sc_testdf,testcat],axis=1)\n",
        "test_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15457, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bynfDfRFc45"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(test_df)\n",
        "test_df = imputer.transform(test_df)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTdp8AEmf3k9"
      },
      "source": [
        "# FEATURE SELECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "7tdu5pP5f3k9",
        "outputId": "47847b4e-e322-41cd-bbdb-dbcef97cf5d8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier();\n",
        "\n",
        "# fit random forest classifier on the training set\n",
        "rfc.fit(train_x, train_y);\n",
        "# extract important features\n",
        "score = np.round(rfc.feature_importances_,3)\n",
        "importances = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
        "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
        "# plot importances\n",
        "plt.rcParams['figure.figsize'] = (50, 50)\n",
        "importances.plot.bar();"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 3600x3600 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw6Fu8CUf3k-",
        "outputId": "0c42ef24-4191-46d4-9430-852011e322d7"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "import itertools\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# create the RFE model and select 10 attributes\n",
        "rfe = RFE(rfc, n_features_to_select=15)\n",
        "rfe = rfe.fit(train_x, train_y)\n",
        "\n",
        "# summarize the selection of the attributes\n",
        "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
        "selected_features = [v for i, v in feature_map if i==True]\n",
        "\n",
        "selected_features"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 5, 6, 7, 13, 15, 17, 27, 37, 38, 39, 51, 52, 62, 78]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nMXEkmff3k_"
      },
      "source": [
        "# DATASET PARTITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP7lktHVf3k_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.10, stratify=train_y, random_state=2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmzoziGf3lA"
      },
      "source": [
        "# FITTING MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzFabFcTf3lA",
        "outputId": "4aab23a6-ca34-427f-9dae-5fb53b764f42"
      },
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn.naive_bayes import BernoulliNB \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train KNeighborsClassifier Model\n",
        "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
        "KNN_Classifier.fit(X_train, Y_train); \n",
        "\n",
        "# Train LogisticRegression Model\n",
        "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=42)\n",
        "LGR_Classifier.fit(X_train, Y_train);\n",
        "\n",
        "# Train Gaussian Naive Baye Model\n",
        "BNB_Classifier = BernoulliNB()\n",
        "BNB_Classifier.fit(X_train, Y_train)\n",
        "            \n",
        "# Train Decision Tree Model\n",
        "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "DTC_Classifier.fit(X_train, Y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyioRLLwf3lB"
      },
      "source": [
        "# EVALUATE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COFgz_A0f3lB",
        "outputId": "7c26ac5f-7521-4c67-8931-e1bd18bd12a2"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "models = []\n",
        "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
        "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
        "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
        "models.append(('LogisticRegression', LGR_Classifier))\n",
        "\n",
        "\n",
        "for i, v in models:\n",
        "    scores = cross_val_score(v, X_train, Y_train, cv=5)\n",
        "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
        "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
        "    print()\n",
        "    print('============================== {} Model Evaluation =============================='.format(i))\n",
        "    print()\n",
        "    print (\"Cross Validation Mean Score:\" \"\\n\", scores)\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================== Naive Baye Classifier Model Evaluation ==============================\n",
            "\n",
            "Cross Validation Mean Score:\n",
            " [0.975 1.    1.    1.    1.   ]\n",
            "\n",
            "Model Accuracy:\n",
            " 0.995\n",
            "\n",
            "Confusion matrix:\n",
            " [[100   0]\n",
            " [  1  99]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.99      1.00      1.00       100\n",
            "  DrDoS_LDAP       1.00      0.99      0.99       100\n",
            "\n",
            "    accuracy                           0.99       200\n",
            "   macro avg       1.00      0.99      0.99       200\n",
            "weighted avg       1.00      0.99      0.99       200\n",
            "\n",
            "\n",
            "\n",
            "============================== Decision Tree Classifier Model Evaluation ==============================\n",
            "\n",
            "Cross Validation Mean Score:\n",
            " [0.975 1.    1.    1.    1.   ]\n",
            "\n",
            "Model Accuracy:\n",
            " 1.0\n",
            "\n",
            "Confusion matrix:\n",
            " [[100   0]\n",
            " [  0 100]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      1.00      1.00       100\n",
            "  DrDoS_LDAP       1.00      1.00      1.00       100\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "\n",
            "============================== KNeighborsClassifier Model Evaluation ==============================\n",
            "\n",
            "Cross Validation Mean Score:\n",
            " [0.975 1.    0.975 0.975 1.   ]\n",
            "\n",
            "Model Accuracy:\n",
            " 0.985\n",
            "\n",
            "Confusion matrix:\n",
            " [[98  2]\n",
            " [ 1 99]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.99      0.98      0.98       100\n",
            "  DrDoS_LDAP       0.98      0.99      0.99       100\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.99      0.98      0.98       200\n",
            "weighted avg       0.99      0.98      0.98       200\n",
            "\n",
            "\n",
            "\n",
            "============================== LogisticRegression Model Evaluation ==============================\n",
            "\n",
            "Cross Validation Mean Score:\n",
            " [0.975 1.    1.    1.    1.   ]\n",
            "\n",
            "Model Accuracy:\n",
            " 1.0\n",
            "\n",
            "Confusion matrix:\n",
            " [[100   0]\n",
            " [  0 100]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      1.00      1.00       100\n",
            "  DrDoS_LDAP       1.00      1.00      1.00       100\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPxt5eoAf3lB"
      },
      "source": [
        "# VALIDATING MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWQwL6f4f3lC",
        "outputId": "a2b8cadd-f133-496a-940a-56f939dd35f4"
      },
      "source": [
        "for i, v in models:\n",
        "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
        "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
        "    print()\n",
        "    print('============================== {} Model Test Results =============================='.format(i))\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()        \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================== Naive Baye Classifier Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 1.0\n",
            "\n",
            "Confusion matrix:\n",
            " [[900   0]\n",
            " [  0 900]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      1.00      1.00       900\n",
            "  DrDoS_LDAP       1.00      1.00      1.00       900\n",
            "\n",
            "    accuracy                           1.00      1800\n",
            "   macro avg       1.00      1.00      1.00      1800\n",
            "weighted avg       1.00      1.00      1.00      1800\n",
            "\n",
            "\n",
            "\n",
            "============================== Decision Tree Classifier Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9844444444444445\n",
            "\n",
            "Confusion matrix:\n",
            " [[872  28]\n",
            " [  0 900]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      0.97      0.98       900\n",
            "  DrDoS_LDAP       0.97      1.00      0.98       900\n",
            "\n",
            "    accuracy                           0.98      1800\n",
            "   macro avg       0.98      0.98      0.98      1800\n",
            "weighted avg       0.98      0.98      0.98      1800\n",
            "\n",
            "\n",
            "\n",
            "============================== KNeighborsClassifier Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9972222222222222\n",
            "\n",
            "Confusion matrix:\n",
            " [[895   5]\n",
            " [  0 900]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      0.99      1.00       900\n",
            "  DrDoS_LDAP       0.99      1.00      1.00       900\n",
            "\n",
            "    accuracy                           1.00      1800\n",
            "   macro avg       1.00      1.00      1.00      1800\n",
            "weighted avg       1.00      1.00      1.00      1800\n",
            "\n",
            "\n",
            "\n",
            "============================== LogisticRegression Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9961111111111111\n",
            "\n",
            "Confusion matrix:\n",
            " [[893   7]\n",
            " [  0 900]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       1.00      0.99      1.00       900\n",
            "  DrDoS_LDAP       0.99      1.00      1.00       900\n",
            "\n",
            "    accuracy                           1.00      1800\n",
            "   macro avg       1.00      1.00      1.00      1800\n",
            "weighted avg       1.00      1.00      1.00      1800\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0d7iurJf3lC"
      },
      "source": [
        "# PREDICTING FOR TEST DATA using KNN\n",
        "pred_knn = KNN_Classifier.predict(test_df)\n",
        "pred_NB = BNB_Classifier.predict(test_df)\n",
        "pred_log = LGR_Classifier.predict(test_df)\n",
        "pred_dt = DTC_Classifier.predict(test_df)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8go3yWUf3lD"
      },
      "source": [
        "# Extracting TP FP TN FN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik5gxa52f3lD",
        "outputId": "70b81e5e-5298-4439-d2ac-8b52a5207da1"
      },
      "source": [
        "def perf_measure(y_actual, y_pred):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)): \n",
        "        if y_actual.iat[i]==y_pred[i]=='BENIGN':\n",
        "           TP += 1\n",
        "        if y_pred[i]=='DrDoS_NetBIOS' and y_actual.iat[i]!=y_pred[i]:\n",
        "           FP += 1\n",
        "        if y_actual.iat[i]==y_pred[i]=='DrDoS_NetBIOS':\n",
        "           TN += 1\n",
        "        if y_pred[i]=='BENIGN' and y_actual.iat[i]!=y_pred[i]:\n",
        "           FN += 1\n",
        "        \n",
        "    return (TP, FP, TN, FN)\n",
        "\n",
        "\n",
        "for i, v in models:\n",
        "    print(\"For model:\", i)\n",
        "    TP, FP, TN, FN = perf_measure(Y_test, v.predict(X_test))\n",
        "    print (\"TP:\", TP, \"\\tFP:\", FP, \"\\t\\tTN:\", TN, \"\\tFN:\", FN)\n",
        "    \n",
        "    # Testing for first row\n",
        "    #print (\"Expected: \", Y_test.iloc[0], \"Predicted: \", v.predict(X_test).reshape(1, -1)[0][0] )\n",
        "    print()\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For model: Naive Baye Classifier\n",
            "TP: 900 \tFP: 0 \t\tTN: 0 \tFN: 0\n",
            "\n",
            "For model: Decision Tree Classifier\n",
            "TP: 872 \tFP: 0 \t\tTN: 0 \tFN: 0\n",
            "\n",
            "For model: KNeighborsClassifier\n",
            "TP: 895 \tFP: 0 \t\tTN: 0 \tFN: 0\n",
            "\n",
            "For model: LogisticRegression\n",
            "TP: 893 \tFP: 0 \t\tTN: 0 \tFN: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nHzp6iwf3lE",
        "outputId": "4e64d824-c64a-4329-d2b0-f5e3772d1ade"
      },
      "source": [
        "# Testing for second row\n",
        "for i, v in models:\n",
        "    print(\"For model: \", i)\n",
        "    print (\"Expected: \", Y_test.iloc[2], \"\\tPredicted: \", v.predict(X_test).reshape(1, -1)[0][2] )\n",
        "    print()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For model:  Naive Baye Classifier\n",
            "Expected:  BENIGN \tPredicted:  BENIGN\n",
            "\n",
            "For model:  Decision Tree Classifier\n",
            "Expected:  BENIGN \tPredicted:  BENIGN\n",
            "\n",
            "For model:  KNeighborsClassifier\n",
            "Expected:  BENIGN \tPredicted:  BENIGN\n",
            "\n",
            "For model:  LogisticRegression\n",
            "Expected:  BENIGN \tPredicted:  BENIGN\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VFGtfdff3lF",
        "outputId": "057383c4-099a-464b-c402-5acc6b8ee7f0"
      },
      "source": [
        "type(Y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4zmcuSmf3lF"
      },
      "source": [
        "# Functions to extract locations of FP, FN as a pandas series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l99aBImf3lF"
      },
      "source": [
        "def find_FP(y_actual, y_pred):\n",
        "    FP = []\n",
        "\n",
        "    for i in range(len(y_pred)): \n",
        "        if y_pred[i]=='DrDoS_NetBIOS' and y_actual.iat[i]!=y_pred[i]:\n",
        "           FP.append(i)   \n",
        "    return (pd.Series(FP))\n",
        "    \n",
        "def find_FN(y_actual, y_pred):\n",
        "    FN = []\n",
        "\n",
        "    for i in range(len(y_pred)): \n",
        "        if y_pred[i]=='BENIGN' and y_actual.iat[i]!=y_pred[i]:\n",
        "           FN.append(i)\n",
        "    return (pd.Series(FN))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU4zamfff3lG"
      },
      "source": [
        "# Combining Naive Bayes and Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97LVwEWPf3lG"
      },
      "source": [
        "## Getting FP and FN row location from NB output as pd.Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z4e0Lobf3lG",
        "outputId": "402e741e-989c-4119-b050-157c0b343af7"
      },
      "source": [
        "FP_NB= find_FP(Y_test, models[0][1].predict(X_test))\n",
        "print(\"Size of number of FP:\", FP_NB.size) \n",
        "FN_NB= find_FN(Y_test, models[0][1].predict(X_test))\n",
        "print(\"Size of number of FN:\", FN_NB.size) \n",
        "\n",
        "# Testing \n",
        "FP_NB.head(4)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of number of FP: 0\n",
            "Size of number of FN: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nd7p8J7f3lH"
      },
      "source": [
        "## Getting FP FN row entry from X_test and Y_test as pd.DataFrame and pd.Series respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDNXQGUOf3lH",
        "outputId": "637edcbc-7c3a-41d8-e995-c0fe935ee11a"
      },
      "source": [
        "X_test_subset=[]\n",
        "Y_test_subset=[]\n",
        "for i in FP_NB:\n",
        "    X_test_subset.append(X_test.iloc[i])\n",
        "    Y_test_subset.append(Y_test.iat[i])\n",
        "for i in FN_NB:\n",
        "    X_test_subset.append(X_test.iloc[i])\n",
        "    Y_test_subset.append(Y_test.iat[i])\n",
        "    \n",
        "X_test_sub=pd.DataFrame(X_test_subset)\n",
        "Y_test_sub=pd.Series(Y_test_subset)\n",
        "print(\"Size of X_test_sub:\", X_test_sub.shape[0]) \n",
        "print(\"Size of Y_test_sub:\", Y_test_sub.size) \n",
        "\n",
        "# To check for each false positive\n",
        "#for i in FP_NB:\n",
        "#    print (\"Expected: \", Y_test.iloc[i], \"Predicted: \", models[1][1].predict(X_test).reshape(1, -1)[0][i] )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of X_test_sub: 0\n",
            "Size of Y_test_sub: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "NetH6L3Sf3lI",
        "outputId": "b0665bd3-ab25-4db9-d3ad-0e744af2c183"
      },
      "source": [
        "print(type(X_test)) \n",
        "X_test.head(4)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>-0.294325</td>\n",
              "      <td>-0.330286</td>\n",
              "      <td>-0.019260</td>\n",
              "      <td>1.354157</td>\n",
              "      <td>-0.163213</td>\n",
              "      <td>2.625079</td>\n",
              "      <td>0.865855</td>\n",
              "      <td>1.568652</td>\n",
              "      <td>3.411627</td>\n",
              "      <td>-0.126405</td>\n",
              "      <td>-0.351537</td>\n",
              "      <td>-0.004190</td>\n",
              "      <td>0.131692</td>\n",
              "      <td>-0.954325</td>\n",
              "      <td>-0.953726</td>\n",
              "      <td>-0.122168</td>\n",
              "      <td>-0.150181</td>\n",
              "      <td>-0.210671</td>\n",
              "      <td>-0.083956</td>\n",
              "      <td>-0.320042</td>\n",
              "      <td>-0.165578</td>\n",
              "      <td>-0.214059</td>\n",
              "      <td>-0.268482</td>\n",
              "      <td>-0.083942</td>\n",
              "      <td>-0.273828</td>\n",
              "      <td>-0.218524</td>\n",
              "      <td>-0.193320</td>\n",
              "      <td>-0.211860</td>\n",
              "      <td>-0.202885</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>-0.062078</td>\n",
              "      <td>-0.954179</td>\n",
              "      <td>6.231168</td>\n",
              "      <td>-1.017756</td>\n",
              "      <td>1.585400</td>\n",
              "      <td>-0.068906</td>\n",
              "      <td>2.688686</td>\n",
              "      <td>3.236305</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.569652</td>\n",
              "      <td>2.312835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.891484</td>\n",
              "      <td>-0.330907</td>\n",
              "      <td>1.568652</td>\n",
              "      <td>-0.004190</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.330286</td>\n",
              "      <td>1.354157</td>\n",
              "      <td>-0.019260</td>\n",
              "      <td>-0.163213</td>\n",
              "      <td>1.848615</td>\n",
              "      <td>-0.037643</td>\n",
              "      <td>-0.204469</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.006018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.007958</td>\n",
              "      <td>1.162800</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>0.035793</td>\n",
              "      <td>0.364133</td>\n",
              "      <td>-0.705872</td>\n",
              "      <td>-1.032072</td>\n",
              "      <td>-1.023071</td>\n",
              "      <td>0.374364</td>\n",
              "      <td>2.145606</td>\n",
              "      <td>-0.351537</td>\n",
              "      <td>0.836697</td>\n",
              "      <td>1.397018</td>\n",
              "      <td>-0.954668</td>\n",
              "      <td>-0.954113</td>\n",
              "      <td>-0.112917</td>\n",
              "      <td>-0.118829</td>\n",
              "      <td>-0.169283</td>\n",
              "      <td>-0.083956</td>\n",
              "      <td>-0.047881</td>\n",
              "      <td>-0.128203</td>\n",
              "      <td>-0.129041</td>\n",
              "      <td>-0.159329</td>\n",
              "      <td>-0.083953</td>\n",
              "      <td>0.111241</td>\n",
              "      <td>-0.038341</td>\n",
              "      <td>-0.059200</td>\n",
              "      <td>-0.083182</td>\n",
              "      <td>-0.039334</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271711</td>\n",
              "      <td>0.981207</td>\n",
              "      <td>-0.954247</td>\n",
              "      <td>2.282551</td>\n",
              "      <td>-1.017756</td>\n",
              "      <td>1.603831</td>\n",
              "      <td>-0.931051</td>\n",
              "      <td>1.127535</td>\n",
              "      <td>0.548696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.755458</td>\n",
              "      <td>-0.432370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.666507</td>\n",
              "      <td>-0.971074</td>\n",
              "      <td>-1.023071</td>\n",
              "      <td>0.836697</td>\n",
              "      <td>0.271711</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.162800</td>\n",
              "      <td>0.035793</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>0.364133</td>\n",
              "      <td>0.656884</td>\n",
              "      <td>-0.111355</td>\n",
              "      <td>1.643421</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.006018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>0.179816</td>\n",
              "      <td>0.062631</td>\n",
              "      <td>-0.019260</td>\n",
              "      <td>-0.667055</td>\n",
              "      <td>-0.129989</td>\n",
              "      <td>-0.821868</td>\n",
              "      <td>-1.032072</td>\n",
              "      <td>-1.032868</td>\n",
              "      <td>0.496044</td>\n",
              "      <td>0.124061</td>\n",
              "      <td>-0.351537</td>\n",
              "      <td>0.323936</td>\n",
              "      <td>0.540585</td>\n",
              "      <td>-0.954736</td>\n",
              "      <td>-0.954474</td>\n",
              "      <td>-0.014549</td>\n",
              "      <td>0.192078</td>\n",
              "      <td>0.169385</td>\n",
              "      <td>-0.083951</td>\n",
              "      <td>0.192968</td>\n",
              "      <td>0.046274</td>\n",
              "      <td>0.306747</td>\n",
              "      <td>0.277729</td>\n",
              "      <td>-0.083953</td>\n",
              "      <td>-0.126388</td>\n",
              "      <td>0.116664</td>\n",
              "      <td>-0.021910</td>\n",
              "      <td>-0.094037</td>\n",
              "      <td>-0.039334</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>-0.000101</td>\n",
              "      <td>-0.954407</td>\n",
              "      <td>-0.209100</td>\n",
              "      <td>-1.017756</td>\n",
              "      <td>-0.732618</td>\n",
              "      <td>-1.079959</td>\n",
              "      <td>0.344140</td>\n",
              "      <td>-0.165607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.755458</td>\n",
              "      <td>-0.432370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.558469</td>\n",
              "      <td>-1.061503</td>\n",
              "      <td>-1.032868</td>\n",
              "      <td>0.323936</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062631</td>\n",
              "      <td>-0.667055</td>\n",
              "      <td>-0.019260</td>\n",
              "      <td>-0.129989</td>\n",
              "      <td>0.656884</td>\n",
              "      <td>-0.113282</td>\n",
              "      <td>-0.204469</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.006018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0.409771</td>\n",
              "      <td>0.534132</td>\n",
              "      <td>0.389280</td>\n",
              "      <td>0.897348</td>\n",
              "      <td>0.305650</td>\n",
              "      <td>0.925235</td>\n",
              "      <td>-1.032072</td>\n",
              "      <td>-0.713304</td>\n",
              "      <td>2.326872</td>\n",
              "      <td>2.618395</td>\n",
              "      <td>-0.351537</td>\n",
              "      <td>1.843183</td>\n",
              "      <td>2.534143</td>\n",
              "      <td>-0.954707</td>\n",
              "      <td>-0.954445</td>\n",
              "      <td>-0.047711</td>\n",
              "      <td>0.099900</td>\n",
              "      <td>0.160829</td>\n",
              "      <td>-0.083951</td>\n",
              "      <td>0.424860</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.168119</td>\n",
              "      <td>0.266074</td>\n",
              "      <td>-0.083953</td>\n",
              "      <td>0.166228</td>\n",
              "      <td>0.196700</td>\n",
              "      <td>0.062434</td>\n",
              "      <td>-0.031703</td>\n",
              "      <td>-0.039334</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>0.320116</td>\n",
              "      <td>-0.954396</td>\n",
              "      <td>0.022671</td>\n",
              "      <td>-1.017756</td>\n",
              "      <td>2.150267</td>\n",
              "      <td>-0.593911</td>\n",
              "      <td>2.240225</td>\n",
              "      <td>2.291911</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.373632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.755458</td>\n",
              "      <td>-0.432370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.558469</td>\n",
              "      <td>-0.741661</td>\n",
              "      <td>-0.713304</td>\n",
              "      <td>1.843183</td>\n",
              "      <td>0.271710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.534132</td>\n",
              "      <td>0.897348</td>\n",
              "      <td>0.389280</td>\n",
              "      <td>0.305650</td>\n",
              "      <td>0.656884</td>\n",
              "      <td>7.917432</td>\n",
              "      <td>0.534687</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>-0.059265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.006018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6   \\\n",
              "457 -0.294325 -0.330286 -0.019260  1.354157 -0.163213  2.625079  0.865855   \n",
              "150  0.007958  1.162800  1.089633  0.035793  0.364133 -0.705872 -1.032072   \n",
              "570  0.179816  0.062631 -0.019260 -0.667055 -0.129989 -0.821868 -1.032072   \n",
              "276  0.409771  0.534132  0.389280  0.897348  0.305650  0.925235 -1.032072   \n",
              "\n",
              "           7         8         9         10        11        12        13  \\\n",
              "457  1.568652  3.411627 -0.126405 -0.351537 -0.004190  0.131692 -0.954325   \n",
              "150 -1.023071  0.374364  2.145606 -0.351537  0.836697  1.397018 -0.954668   \n",
              "570 -1.032868  0.496044  0.124061 -0.351537  0.323936  0.540585 -0.954736   \n",
              "276 -0.713304  2.326872  2.618395 -0.351537  1.843183  2.534143 -0.954707   \n",
              "\n",
              "           14        15        16        17        18        19        20  \\\n",
              "457 -0.953726 -0.122168 -0.150181 -0.210671 -0.083956 -0.320042 -0.165578   \n",
              "150 -0.954113 -0.112917 -0.118829 -0.169283 -0.083956 -0.047881 -0.128203   \n",
              "570 -0.954474 -0.014549  0.192078  0.169385 -0.083951  0.192968  0.046274   \n",
              "276 -0.954445 -0.047711  0.099900  0.160829 -0.083951  0.424860  0.000027   \n",
              "\n",
              "           21        22        23        24        25        26        27  \\\n",
              "457 -0.214059 -0.268482 -0.083942 -0.273828 -0.218524 -0.193320 -0.211860   \n",
              "150 -0.129041 -0.159329 -0.083953  0.111241 -0.038341 -0.059200 -0.083182   \n",
              "570  0.306747  0.277729 -0.083953 -0.126388  0.116664 -0.021910 -0.094037   \n",
              "276  0.168119  0.266074 -0.083953  0.166228  0.196700  0.062434 -0.031703   \n",
              "\n",
              "           28        29   30   31   32        33        34        35  \\\n",
              "457 -0.202885 -0.373632  0.0  0.0  0.0  0.271710 -0.062078 -0.954179   \n",
              "150 -0.039334 -0.373632  0.0  0.0  0.0  0.271711  0.981207 -0.954247   \n",
              "570 -0.039334 -0.373632  0.0  0.0  0.0  0.271710 -0.000101 -0.954407   \n",
              "276 -0.039334 -0.373632  0.0  0.0  0.0  0.271710  0.320116 -0.954396   \n",
              "\n",
              "           36        37        38        39        40        41   42   43  \\\n",
              "457  6.231168 -1.017756  1.585400 -0.068906  2.688686  3.236305  0.0  0.0   \n",
              "150  2.282551 -1.017756  1.603831 -0.931051  1.127535  0.548696  0.0  0.0   \n",
              "570 -0.209100 -1.017756 -0.732618 -1.079959  0.344140 -0.165607  0.0  0.0   \n",
              "276  0.022671 -1.017756  2.150267 -0.593911  2.240225  2.291911  0.0  0.0   \n",
              "\n",
              "           44   45        46        47   48   49        50        51  \\\n",
              "457 -0.373632  0.0 -0.569652  2.312835  0.0  0.0  3.891484 -0.330907   \n",
              "150 -0.373632  0.0  1.755458 -0.432370  0.0  0.0  1.666507 -0.971074   \n",
              "570 -0.373632  0.0  1.755458 -0.432370  0.0  0.0 -0.558469 -1.061503   \n",
              "276 -0.373632  0.0  1.755458 -0.432370  0.0  0.0 -0.558469 -0.741661   \n",
              "\n",
              "           52        53        54   55   56   57   58   59   60        61  \\\n",
              "457  1.568652 -0.004190  0.271710  0.0  0.0  0.0  0.0  0.0  0.0 -0.330286   \n",
              "150 -1.023071  0.836697  0.271711  0.0  0.0  0.0  0.0  0.0  0.0  1.162800   \n",
              "570 -1.032868  0.323936  0.271710  0.0  0.0  0.0  0.0  0.0  0.0  0.062631   \n",
              "276 -0.713304  1.843183  0.271710  0.0  0.0  0.0  0.0  0.0  0.0  0.534132   \n",
              "\n",
              "           62        63        64        65        66        67        68  \\\n",
              "457  1.354157 -0.019260 -0.163213  1.848615 -0.037643 -0.204469  0.272238   \n",
              "150  0.035793  1.089633  0.364133  0.656884 -0.111355  1.643421  0.272238   \n",
              "570 -0.667055 -0.019260 -0.129989  0.656884 -0.113282 -0.204469  0.272238   \n",
              "276  0.897348  0.389280  0.305650  0.656884  7.917432  0.534687  0.272238   \n",
              "\n",
              "           69   70        71        72        73   74        75        76  \\\n",
              "457 -0.059265  0.0 -0.059265 -0.059265 -0.059265  0.0 -0.059265 -0.059265   \n",
              "150 -0.059265  0.0 -0.059265 -0.059265 -0.059265  0.0 -0.059265 -0.059265   \n",
              "570 -0.059265  0.0 -0.059265 -0.059265 -0.059265  0.0 -0.059265 -0.059265   \n",
              "276 -0.059265  0.0 -0.059265 -0.059265 -0.059265  0.0 -0.059265 -0.059265   \n",
              "\n",
              "      77        78  \n",
              "457  0.0 -1.006018  \n",
              "150  0.0 -1.006018  \n",
              "570  0.0 -1.006018  \n",
              "276  0.0 -1.006018  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "GO0-cOvwf3lI",
        "outputId": "77ef3ae2-2c83-4190-d250-8c9f9cdd99f8"
      },
      "source": [
        "print(type(X_test_sub))\n",
        "X_test_sub.head(4)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27aPJVEif3lI",
        "outputId": "245daeea-5f84-4c7e-c84e-f690a80515ea"
      },
      "source": [
        "print(type(Y_test)) \n",
        "Y_test.head(4)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "457    BENIGN\n",
              "150    BENIGN\n",
              "570    BENIGN\n",
              "276    BENIGN\n",
              "Name:  Label, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWRXs0Emf3lI",
        "outputId": "c08eb076-42a3-48f7-b613-010b4ca0da4c"
      },
      "source": [
        "print(type(Y_test_sub))\n",
        "Y_test_sub.head(4)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuIqnntPf3lK"
      },
      "source": [
        "# Validating the combined model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfGZTBGvf3lK"
      },
      "source": [
        "## Validating results for the FP FN subset in the combined model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "C6Th70mUf3lK",
        "outputId": "03a8ae48-e5e3-445b-e4ea-32412037d5bb"
      },
      "source": [
        "accuracy = metrics.accuracy_score(Y_test_sub, models[1][1].predict(X_test_sub))\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test_sub, models[1][1].predict(X_test_sub))\n",
        "classification = metrics.classification_report(Y_test_sub, models[1][1].predict(X_test_sub))\n",
        "print()\n",
        "print('============================== {} Model Test Results =============================='.format(\"NB -> DT\"))\n",
        "print()\n",
        "print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "print()\n",
        "print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "print()\n",
        "print(\"Classification report:\" \"\\n\", classification) \n",
        "print() "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-169cd2bbf9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'============================== {} Model Test Results =============================='\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NB -> DT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-seZhSmf3lK"
      },
      "source": [
        "## Validating hybrid model, NB + DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "e2h7wrhcf3lK",
        "outputId": "aabcabf4-584f-4ee7-f5a4-012d2241032e"
      },
      "source": [
        "print(\"For Naive Bayes:\")\n",
        "TP_old, FP_old, TN_old, FN_old = perf_measure(Y_test, BNB_Classifier.predict(X_test))\n",
        "print (\"TP:\", TP_old, \"\\tFP:\", FP_old, \"\\t\\tTN:\", TN_old, \"\\tFN:\", FN_old)\n",
        "\n",
        "print()\n",
        "print(\"For Naive Bayes -> Decision Tress:\")\n",
        "TP_new, FP_new, TN_new, FN_new = perf_measure(Y_test_sub, DTC_Classifier.predict(X_test_sub))\n",
        "print (\"TP:\", TP_new, \"\\tFP:\", FP_new, \"\\t\\tTN:\", TN_new, \"\\tFN:\", FN_new)\n",
        "\n",
        "print()\n",
        "print(\"For Naive Bayes + Decision Tress:\")\n",
        "tp = TP_old +TP_new\n",
        "fp = FP_new\n",
        "tn = TN_old +TN_new\n",
        "fn = FN_new\n",
        "print (\"TP:\", tp, \"\\tFP:\", fp, \"\\t\\tTN:\", tn, \"\\tFN:\", fn)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Naive Bayes:\n",
            "TP: 900 \tFP: 0 \t\tTN: 0 \tFN: 0\n",
            "\n",
            "For Naive Bayes -> Decision Tress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9d53e258857f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For Naive Bayes -> Decision Tress:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mTP_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTN_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDTC_Classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"TP:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTP_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tFP:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\\tTN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTN_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tFN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUG62jF4f3lK"
      },
      "source": [
        "## 1. Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\n",
        "## 2. Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN\n",
        "## 3. Precision (true positives / predicted positives) = TP / TP + FP\n",
        "## 4. Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN\n",
        "## 5. Specificity (true negatives / all actual negatives) =TN / TN + FP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "hHa3lcN_f3lK",
        "outputId": "5d8c0e4c-b0bc-48e7-a9b9-f5274401e7eb"
      },
      "source": [
        "acc_old= (TP_old + TN_old) / (TP_old + FP_old + TN_old + FN_old)\n",
        "mis_old= (FP_old + FN_old) / (TP_old + FP_old + TN_old + FN_old)\n",
        "prec_old= TP_old / (TP_old + FP_old)\n",
        "sen_old= TP_old / (TP_old + FN_old)\n",
        "spec_old= TN_old / (TN_old + FP_old)\n",
        "\n",
        "acc= (tp + tn) / (tp + fp + tn + fn)\n",
        "mis= (fp + fn) / (tp + fp + tn + fn)\n",
        "prec= tp / (tp + fp)\n",
        "sen= tp / (tp + fn)\n",
        "spec= tn / (tn + fp)\n",
        "\n",
        "print (\"Accuracy\")\n",
        "print (\"Old: \", acc_old, \"\\tNew: \", acc)\n",
        "print (\"\\nMisclassification\")\n",
        "print (\"Old: \", mis_old, \"\\tNew: \", mis)\n",
        "print (\"\\nPrecision\")\n",
        "print (\"Old: \", prec_old, \"\\tNew: \", prec)\n",
        "print (\"\\nSensitivity\")\n",
        "print (\"Old: \", sen_old, \"\\tNew: \", sen)\n",
        "print (\"\\nSpecificity\")\n",
        "print (\"Old: \", spec_old, \"\\tNew: \", spec)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4caff677533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc_old\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN_old\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmis_old\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN_old\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprec_old\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTP_old\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msen_old\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTP_old\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspec_old\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTN_old\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTN_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TP_old' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmOmpn_hf3lL"
      },
      "source": [
        "# Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tun2RFQf3lM"
      },
      "source": [
        "# set width of bar\n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(12, 8))\n",
        " \n",
        "# set height of bar\n",
        "NB = [TP_old, FP_old, TN_old, FN_old]\n",
        "NBandDT = [tp, fp, tn, fn]\n",
        " \n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(NB))\n",
        "br2 = [x + barWidth for x in br1]\n",
        " \n",
        "# Make the plot\n",
        "plt.bar(br1, NB, color ='b', width = barWidth, edgecolor ='grey', label ='Naive Bayes')\n",
        "plt.bar(br2, NBandDT, color ='g', width = barWidth, edgecolor ='grey', label ='Naive Bayes and Decision Tree')\n",
        " \n",
        "# Adding Xticks\n",
        "plt.xlabel('Confusion Matrix Element', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('Value', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + barWidth for r in range(len(NB))], ['TP', 'FP', 'TN', 'FN'])\n",
        " \n",
        "plt.legend()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gdJiifKf3lN"
      },
      "source": [
        "# set width of bar\n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(12, 8))\n",
        " \n",
        "# set height of bar\n",
        "Old = [acc_old, mis_old, prec_old, sen_old, spec_old]\n",
        "New = [acc, mis, prec, sen, spec]\n",
        " \n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(Old))\n",
        "br2 = [x + barWidth for x in br1]\n",
        " \n",
        "# Make the plot\n",
        "plt.bar(br1, Old, color ='b', width = barWidth, edgecolor ='grey', label ='Old')\n",
        "plt.bar(br2, New, color ='g', width = barWidth, edgecolor ='grey', label ='New')\n",
        "\n",
        "\n",
        "# Adding Xticks\n",
        "plt.xlabel('Performance Metrics', fontweight ='bold', fontsize = 15)\n",
        "plt.ylabel('Value', fontweight ='bold', fontsize = 15)\n",
        "plt.xticks([r + barWidth for r in range(len(NB))], ['Accuracy', 'Misclassification', 'Precision', 'Sensitivity', 'Specificity'])\n",
        " \n",
        "plt.legend()\n",
        "plt.title(\"Comparison of performance metrics\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtbGFX-4f3lN"
      },
      "source": [
        "accPercent= ((acc- acc_old)/acc_old) *100\n",
        "misPercent= ((mis_old- mis)/mis_old) *100\n",
        "precPercent= ((prec- prec_old)/prec_old) *100\n",
        "senPercent= ((sen- sen_old)/sen_old) *100\n",
        "specPercent= ((spec- spec_old)/spec_old) *100\n",
        "\n",
        "print (\"Accuracy increase percentage: \" ,accPercent, \"%\")\n",
        "print (\"Missclasification decrease percentage: \" ,misPercent, \"%\")\n",
        "print (\"Precison increase percentage: \", precPercent, \"%\")\n",
        "print (\"Sensitivity increase percentage: \", senPercent, \"%\")\n",
        "print (\"Specificity increase percentage: \", specPercent, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}